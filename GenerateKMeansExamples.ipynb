{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "852919c8-c4ba-4115-99d1-3ee1cc78d413",
   "metadata": {},
   "source": [
    "### Generate k-means datasets for practice\n",
    "### Bill Nicholson\n",
    "### nicholdw@ucmail.uc.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88d0276c-fdda-4ffa-9846-f380f9a9846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "import colorsys\n",
    "from random import randrange\n",
    "from datetime import timedelta\n",
    "from datetime import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "354a70b2-ba5a-4956-adf8-324a08194b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(msg, fileName, mode):\n",
    "    # mode: 'w' = write, 'a+' = append\n",
    "    with open('fileName.txt', 'w') as f:\n",
    "        print('Filename:', filename, file=f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "642e9d6b-5bcb-414f-92f6-bbcf5ca6238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/470690/how-to-automatically-generate-n-distinct-colors/30881059#30881059\n",
    "def get_colors(num_colors):\n",
    "    colors=[]\n",
    "    for i in np.arange(0., 360., 360. / num_colors):\n",
    "        hue = i/360.\n",
    "        lightness = (50 + np.random.rand() * 10)/100.\n",
    "        saturation = (90 + np.random.rand() * 10)/100.\n",
    "        colors.append(colorsys.hls_to_rgb(hue, lightness, saturation))\n",
    "        #print(\"get_colors(\", num_colors, \"): Computed colors:\", colors)\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad50dc2e-d199-4450-b88d-fa9cf2823b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEuclideanDistance(p1, p2):\n",
    "    euclideanDistance = sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)\n",
    "    return euclideanDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe54a4dd-5fda-4bf5-b11e-270ea8726a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def targetClusterToString(targetCluster):\n",
    "    toString = \"\"\n",
    "    delimiter = \"\"\n",
    "    for key in targetCluster.keys():\n",
    "        toString += delimiter + key + \":\" + str(targetCluster[key])\n",
    "        delimiter = \"-\"\n",
    "    return \"(\" + toString + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8149ca5-c920-4d72-b8b4-482f081e7639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirtyUpTheData(dataPoint):\n",
    "    if random.randint(0,100) > 95:\n",
    "        #howMessedUp = random.randint(0,3)\n",
    "        tmp = random.choice([0, \"None\", 1, np.NaN, \" \"])\n",
    "    else:\n",
    "        tmp = dataPoint\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13368efa-5b3c-4009-b241-6fad28064650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomDate(startDateString, endDateString):\n",
    "    \"\"\"\n",
    "    This function will return a random datetime between two datetime objects.\n",
    "    \"\"\"\n",
    "    startDate = datetime.strptime(startDateString, '%Y-%m-%d')\n",
    "    endDate = datetime.strptime(endDateString, '%Y-%m-%d')\n",
    "    deltaDays = endDate - startDate\n",
    "    #print(deltaDays, type(deltaDays))\n",
    "    randomDays = randrange(deltaDays.days)\n",
    "    return (startDate + timedelta(days = randomDays)).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ea5b89c-781a-4768-9e11-ed650bbd89b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDatasets(practiceDatasets):\n",
    "    for file in practiceDatasets[\"files\"]:\n",
    "        mode = \"w\"\n",
    "        mySeed = 42                # Default\n",
    "        myDistribution = \"normal\"  # Default\n",
    "        logFile = None\n",
    "        logFileName = None\n",
    "        mySigma = 100            # Wild guess\n",
    "        makeItDirty = False\n",
    "        #print(\"seed =\", file[\"seed\"])\n",
    "        if file.get(\"seed\") != None: mySeed = int(file[\"seed\"])\n",
    "        if file.get(\"sigma\") != None: mySigma = int(file[\"sigma\"])\n",
    "        if file.get(\"totalpoints\") != None: numberOfRows = int(file[\"totalpoints\"])\n",
    "        if file.get(\"makeitdirty\") != None: \n",
    "            tmp = file[\"makeitdirty\"]\n",
    "            if tmp.lower() in ['true', '1', 't', 'y', 'yes', 'yeah', 'yup', 'certainly', 'uh-huh', 'ok', '-1']:\n",
    "                makeItDirty = True\n",
    "            else:\n",
    "                makeItDirty = False\n",
    "        # Gaussian doesn't work so don't use it\n",
    "        #if file.get(\"distribution\") != None: myDistribution = file[\"distribution\"]\n",
    "        random.seed(mySeed)\n",
    "        columnsToCluster = OrderedDict()\n",
    "        optimalClusters = int(file[\"optimal clusters\"])\n",
    "        targetClusters = []  # Will be populated as a list of dictionaries. Each sub dictionary is a point on the graph (x,y)\n",
    "        fileName = file[\"fileName\"]\n",
    "        logFileHandle = open(fileName + '.txt', 'w') \n",
    "        print(\"Creating\", fileName+\".csv\", \"optimal clusters = \", optimalClusters, file = logFileHandle)\n",
    "        print(\"makeitdirty =\", makeItDirty, file = logFileHandle)\n",
    "        print(\"seed =\", mySeed, file = logFileHandle)\n",
    "        print(\"distribution =\", myDistribution, file = logFileHandle)\n",
    "        print(\"total points =\", numberOfRows, file = logFileHandle)\n",
    "        if myDistribution == \"gaussian\": print(\"sigma =\", mySigma, file = logFileHandle)\n",
    "        headerRow = [str(x) for x in file[\"columns\"].keys()]\n",
    "        headerRow = \",\".join(headerRow) + \",\" + \"Target Centroid\"\n",
    "        print(\"Header row = \", headerRow, file = logFileHandle)\n",
    "        with open(fileName + \".csv\", mode) as f:\n",
    "            if mode == \"w\":\n",
    "                f.write(headerRow)\n",
    "                f.write(\"\\n\")\n",
    "            for column in file[\"columns\"]:\n",
    "                if column in file[\"columns to cluster\"]:\n",
    "                    columnsToCluster[column] = file[\"columns\"][column]\n",
    "            print(\"Columns to cluster:\", columnsToCluster, file = logFileHandle)\n",
    "            if columnsToCluster == []:\n",
    "                raise Exception(\"No columns to cluster were found in the meta data.\")\n",
    "            # Compute the centroids around which the clusters will form\n",
    "            for i in range(0, int(optimalClusters)):\n",
    "                # we need a randomly generated (x, y) for the cluster.\n",
    "                # x and y are the two columns we are operating on as specified in \"columns to cluster\" in the meta data file\n",
    "                # for that we need the max/min for x and y\n",
    "                point = OrderedDict()\n",
    "\n",
    "                for key in columnsToCluster.keys():\n",
    "                    max = int(columnsToCluster[key][\"max\"])\n",
    "                    min = int(columnsToCluster[key][\"min\"])\n",
    "                    dataType = \"int\"\n",
    "                    decimalPlaces = 2\n",
    "                    if columnsToCluster[key].get(\"datatype\") != None:\n",
    "                        dataType = columnsToCluster[key][\"datatype\"]\n",
    "                    if columnsToCluster[key].get(\"decimalplaces\") != None:\n",
    "                        dataType = columnsToCluster[key][\"decimalplaces\"]\n",
    "                    # We need some random value in the range (max,min) that is sufficiently far enough away from the other clusters we are generating here\n",
    "                    # Nudge the points away from the edges\n",
    "                    featureRange = int(max) - int(min)\n",
    "                    featureMiddle = int(min) + (featureRange / 2)\n",
    "                    #point[key] = featureMiddle + int(random.uniform(-.3, .3) * featureRange)\n",
    "                    lower = int(int(min) + (featureRange * .23))\n",
    "                    upper = int(int(max) - (featureRange * .23))\n",
    "                    #print(\"key\", key, \"min\", min, \"max\", max, \"upper\", upper, \"lower\", lower)\n",
    "                    point[key] = random.randint(lower, upper)\n",
    "                    #print(\"key =\", key, \"max = \", max, \"min =\", min, \"featureRange =\", featureRange, \"featureMiddle =\", featureMiddle)\n",
    "                    #print(\"upper =\", upper, \"lower =\", lower, \"co-ordinate =\", point[key]) \n",
    "                #print(\"target cluster:\", point)\n",
    "                targetClusters.append(point)\n",
    "\n",
    "            print(\"Target clusters computed to be:\", file = logFileHandle)\n",
    "            for targetCluster in targetClusters:\n",
    "                print(targetCluster, file = logFileHandle)\n",
    "            for rowNumber in range(0, int(numberOfRows/optimalClusters)):\n",
    "                for i in range(0, len(targetClusters)):\n",
    "                    row = OrderedDict()  # The row of data we will write to the CSV file at the bottom of this loop\n",
    "                    for columnName in file[\"columns\"]:\n",
    "                        # column is a dictionary\n",
    "                        #print(column, \":\", file[\"columns\"][column])\n",
    "                        column = file[\"columns\"][columnName]\n",
    "                        if chooseFromList := column.get(\"choosefromlist\") != None:    # Walrus operator!\n",
    "                            row[columnName] = random.choice(column[\"choosefromlist\"])\n",
    "                        else:\n",
    "                            # Do not convert from string, yet. We don't know what data type we are working with. Could be a date.\n",
    "                            max = column[\"max\"]\n",
    "                            min = column[\"min\"]\n",
    "                            dataType = \"int\"\n",
    "                            #print(\"Looking for datatype in \", column)\n",
    "                            if column.get(\"datatype\") != None:\n",
    "                                dataType = column[\"datatype\"]\n",
    "                                #print(\"Found datatype in\", column, \", set to\", dataType)\n",
    "                            decimalPlaces = 2\n",
    "                            if column.get(\"decimalplaces\") != None:\n",
    "                                decimalPlaces = column[\"decimalplaces\"]\n",
    "                            increment = column[\"increment\"]\n",
    "                            if dataType == \"float\":\n",
    "                                value = round(random.uniform(int(min), int(max)), decimalPlaces)\n",
    "                                #print(\"found float data type in \", column, \"generated value =\", value)\n",
    "                            elif dataType == \"int\":\n",
    "                                value = random.randint(int(min), int(max))\n",
    "                            elif dataType == \"date\":\n",
    "                                value = getRandomDate(str(min), str(max))\n",
    "                            elif dataType == \"time\":\n",
    "                                pass\n",
    "                            else:\n",
    "                                print(\"Invalid Data Type (\", datatype, \")\")\n",
    "                            row[columnName] = value   # Don't make it a string! \n",
    "                    # Now we have a randomly generated row but we do not know if it's near any of our centroid points\n",
    "                    #print(\"before:\", row)\n",
    "                    newValues = dict()\n",
    "                    randomTargetCluster = random.choice(targetClusters)\n",
    "                    row[\"Target Cluster\"] = targetClusterToString(randomTargetCluster)\n",
    "                    for column in columnsToCluster.keys():\n",
    "                        #x = row[column]\n",
    "                        # Get the vaules of the centroid, then we will nudge the values in our current row to be inthe neighborhood of that point\n",
    "                        newValues[column] = randomTargetCluster[column]\n",
    "                    for key in newValues.keys():\n",
    "                        if myDistribution == \"normal\":\n",
    "                            increment = (newValues[key] * random.uniform(-.2, .2))\n",
    "                            # At this time the only data types for cluster dimensions are int and float\n",
    "                            #print(\"row[\",key,\"]:\", row[key], type(row[key]), \", \",  isinstance(row[key], int))\n",
    "                            if isinstance(row[key], int):\n",
    "                                row[key] = int(newValues[key] + increment)\n",
    "                            else:\n",
    "                                # ToDo Need to round here according to decimalplaces value in the metadata, not hard-coded to 2\n",
    "                                row[key] = round(float(newValues[key] + increment), 2)\n",
    "                        elif myDistribution == \"gaussian\":\n",
    "                            mu = 5  #randomTargetCluster[key]\n",
    "                            row[key] = newValues[key] + (int(random.gauss(mu, sigma)))                           \n",
    "                        if random.random() > .90:\n",
    "                            randomness = int(row[key] * random.random()) * random.randint(-1, 1)\n",
    "                            tmp = row[key] + randomness\n",
    "                            #print(\"row =\", row, \"\\n  key =\", key, \"row[key] =\", row[key], \"randomness =\", randomness, tmp =\", tmp)\n",
    "                            if tmp >= int(file[\"columns\"][key][\"min\"]) and tmp <= int(file[\"columns\"][key][\"max\"]):\n",
    "                                row[key] = tmp\n",
    "                                #print(\"Adding \", increment, \"to get\", row[key] + tmp)\n",
    "                    #print(\"after:\", row)\n",
    "                    rowString = \"\"\n",
    "                    comma = \"\"\n",
    "                    #print(row)\n",
    "                    #break\n",
    "                    for key in row.keys():\n",
    "                        if makeItDirty and key != \"Target Cluster\":\n",
    "                            tmp = dirtyUpTheData(row[key])\n",
    "                        else:\n",
    "                            tmp = row[key]\n",
    "                        rowString += comma + str(tmp)\n",
    "                        comma = \",\"\n",
    "                    f.write(rowString)\n",
    "                    f.write(\"\\n\")\n",
    "            f.close()\n",
    "    logFileHandle.close()\n",
    "    return fileName"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be7ffc8-3536-4d85-b2fb-72c58766f13f",
   "metadata": {},
   "source": [
    "### Test one of the data files we generated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d900d69-e5f1-46f9-8978-4087e7b2b5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testOurGeneratedDataFile(fileName):\n",
    "    myDF = pd.read_csv(fileName + \".csv\")\n",
    "    # drop all the columns except the two we are fitting to\n",
    "    myDF = myDF[[\"square feet\", \"annual property tax\"]]\n",
    "    #myDF.drop([\"bathrooms\", \"lot size\", \"Target Centroid\"], axis=1, inplace=True)\n",
    "    logFileHandle = open(fileName + '.txt', 'a+') \n",
    "    #print(myDF.head())\n",
    "    inertias = []\n",
    "    myRange = range(1,11)\n",
    "    for i in myRange:\n",
    "        kmeans = KMeans(n_clusters=i)\n",
    "        kmeans.fit(myDF)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "\n",
    "    plt.plot(myRange, inertias, marker='o')\n",
    "    plt.title('Elbow method')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.rcParams['figure.figsize'] = [18, 18]  # I don't know why this works but it does seem to pleasingly resize the subplots\n",
    "    plt.show()\n",
    "    \n",
    "    # Scatter plot of the DataFrame overlaid with the scatter plot of the centroids (K-means)\n",
    "    # We will guess there are three clusters: that should match the \"optimal clusters\" value in the meta data file\n",
    "    kmeans = KMeans(n_clusters = 3)\n",
    "    #print(myDF.describe())\n",
    "    kmeans.fit(myDF)\n",
    "\n",
    "    # The labels_ property is an array of integers indicating the centroid to which each data point has been assigned.\n",
    "    #print(\"kmeans.labels_ =\", kmeans.labels_)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_ylabel(\"Property Tax\")\n",
    "    ax.set_xlabel(\"Square Feet\")\n",
    "    plt.scatter(myDF['square feet'], myDF['annual property tax'], c=kmeans.labels_)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    #print(\"Data type of centroid data:\", type(centroids))\n",
    "    print(\"Actual shape of centroid data:\", centroids.shape, file = logFileHandle)\n",
    "    print(\"Actual centroids computed by fit method:\", file = logFileHandle)\n",
    "    for centroid in centroids:\n",
    "        print(type(centroid), centroid, file = logFileHandle)\n",
    "    plt.scatter(centroids[:,0] , centroids[:,1] , s = 160, c=get_colors(len(centroids))) # color = myColors)\n",
    "    plt.show()\n",
    "\n",
    "    # Save a a copy of our definitive centroids for possible classification later.\n",
    "    happyCentroids = kmeans.cluster_centers_    \n",
    "    logFileHandle.close()\n",
    "\n",
    "    # Plot all the points in the same color just to get a feel for the points without classificaiton\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_ylabel(\"Property Tax\")\n",
    "    ax.set_xlabel(\"Square Feet\")\n",
    "    plt.scatter(myDF['square feet'], myDF['annual property tax'])\n",
    "    plt.show()\n",
    "\n",
    "    # Would be interesting: plot points in each classifications in a different color using the original centroids in the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f52889f-c3a4-41ae-a3c0-296fefe74882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploreACSVFileWithDirtyData(fileName):\n",
    "    myDF = pd.read_csv(fileName + \".csv\")\n",
    "    print(myDF.info())\n",
    "    print(myDF.describe())\n",
    "    print(myDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8140952-8da1-42d3-ac08-3be5e73e6ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    fileHandle = open(\"PracticeDatasetsMetaData.json\")\n",
    "    practiceDatasets = json.load(fileHandle)\n",
    "    #print(practiceDatasets)\n",
    "    generateDatasets(practiceDatasets)\n",
    "    #testOurGeneratedDataFile(\"houses\")\n",
    "    #exploreACSVFileWithDirtyData(\"carsDirtyData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ba45470-9721-43f7-bc1d-8bc25a055f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Experimenting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79fa5b5-a7d7-499e-988e-41f94e0eb4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
